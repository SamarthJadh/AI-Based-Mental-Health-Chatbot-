{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "M3RJvVwhbfuo"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download('wordnet', quiet=True)\n",
        "import json\n",
        "import random\n",
        "import pickle\n",
        "# from google.colab import files\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "id": "YMITwoHMjNK5",
        "outputId": "45b6e7c9-4745-426b-ea90-388dec8eb3bf"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'files' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m corpus \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      7\u001b[0m ignored_tokens \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m?\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m!\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m----> 9\u001b[0m uploaded_file \u001b[38;5;241m=\u001b[39m \u001b[43mfiles\u001b[49m\u001b[38;5;241m.\u001b[39mupload()\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     12\u001b[0m     filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(uploaded_file))\n",
            "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
          ]
        }
      ],
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "#Lists to store vocabulary, labels (intents), and tokenized patterns\n",
        "vocab = []\n",
        "labels = []\n",
        "corpus = []\n",
        "ignored_tokens = ['?', '!']\n",
        "\n",
        "uploaded_file = files.upload()\n",
        "\n",
        "try:\n",
        "    filename = next(iter(uploaded_file))\n",
        "    with open(filename, 'r') as f:\n",
        "        file_content = f.read()\n",
        "    data = json.loads(file_content)\n",
        "except Exception as error:\n",
        "    print(f\"Error loading the file: {error}\")\n",
        "    raise\n",
        "\n",
        "for item in data.get('intents', []):\n",
        "    for sentence in item.get('patterns', []):\n",
        "        #Tokenize each pattern(split into individual words)\n",
        "        tokens = nltk.word_tokenize(sentence)\n",
        "        vocab.extend(tokens)  #Add tokens to vocabulary list\n",
        "        corpus.append((tokens, item['tag']))  # Add tokenized sentence with its label\n",
        "\n",
        "        # Add unique tags(intents) to labels list\n",
        "        if item['tag'] not in labels:\n",
        "            labels.append(item['tag'])\n",
        "\n",
        "#Normalize the vocabulary by lemmatizing,converting to lowercase and removing ignored tokens\n",
        "vocab = sorted(set([lemmatizer.lemmatize(token.lower()) for token in vocab if token not in ignored_tokens]))\n",
        "\n",
        "#Sort the labels\n",
        "labels = sorted(set(labels))\n",
        "\n",
        "#Output statistics aboutthe processed data\n",
        "print(f\"Processed {len(corpus)} patterns.\")\n",
        "print(f\"Identified {len(labels)} unique intents: {labels}\")\n",
        "print(f\"Found {len(vocab)} unique vocabulary words: {vocab}\")\n",
        "\n",
        "with open('processed_words.pkl', 'wb') as word_file:\n",
        "    pickle.dump(vocab, word_file)\n",
        "\n",
        "with open('processed_labels.pkl', 'wb') as label_file:\n",
        "    pickle.dump(labels, label_file)\n",
        "\n",
        "print(\"Data has been saved into pickle files.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "rhMyGYfgjvBZ",
        "outputId": "04abc780-feab-44ab-a89c-efa7564ef1f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data is ready.\n",
            "Epoch 1/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step - accuracy: 0.0283 - loss: 4.3733\n",
            "Epoch 2/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.0398 - loss: 4.3050\n",
            "Epoch 3/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0622 - loss: 4.1790\n",
            "Epoch 4/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.0451 - loss: 4.0102\n",
            "Epoch 5/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - accuracy: 0.1190 - loss: 3.8952\n",
            "Epoch 6/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.0812 - loss: 3.7708\n",
            "Epoch 7/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.1089 - loss: 3.6039\n",
            "Epoch 8/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1381 - loss: 3.3967\n",
            "Epoch 9/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.1809 - loss: 3.1937\n",
            "Epoch 10/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.1893 - loss: 3.0979\n",
            "Epoch 11/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3165 - loss: 2.8747\n",
            "Epoch 12/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2793 - loss: 2.8088\n",
            "Epoch 13/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.2400 - loss: 2.8894\n",
            "Epoch 14/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3312 - loss: 2.5173\n",
            "Epoch 15/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3170 - loss: 2.5957\n",
            "Epoch 16/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4101 - loss: 2.2476\n",
            "Epoch 17/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3454 - loss: 2.4945\n",
            "Epoch 18/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.3220 - loss: 2.2655\n",
            "Epoch 19/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.3573 - loss: 2.3263\n",
            "Epoch 20/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4339 - loss: 2.1592\n",
            "Epoch 21/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4444 - loss: 1.9807\n",
            "Epoch 22/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5228 - loss: 1.6448\n",
            "Epoch 23/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.4509 - loss: 1.7975\n",
            "Epoch 24/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5147 - loss: 1.7451\n",
            "Epoch 25/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5666 - loss: 1.7154\n",
            "Epoch 26/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5386 - loss: 1.4883\n",
            "Epoch 27/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6098 - loss: 1.4474\n",
            "Epoch 28/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5050 - loss: 1.6543\n",
            "Epoch 29/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5137 - loss: 1.5710\n",
            "Epoch 30/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6156 - loss: 1.3233\n",
            "Epoch 31/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5141 - loss: 1.5093\n",
            "Epoch 32/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6887 - loss: 1.1434\n",
            "Epoch 33/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6138 - loss: 1.2779\n",
            "Epoch 34/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5686 - loss: 1.3054\n",
            "Epoch 35/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6814 - loss: 1.2667\n",
            "Epoch 36/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7087 - loss: 1.0680\n",
            "Epoch 37/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6550 - loss: 1.1436\n",
            "Epoch 38/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7224 - loss: 0.9644\n",
            "Epoch 39/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6556 - loss: 1.0981\n",
            "Epoch 40/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6910 - loss: 1.0527\n",
            "Epoch 41/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6993 - loss: 1.0480\n",
            "Epoch 42/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.6632 - loss: 1.1354\n",
            "Epoch 43/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7604 - loss: 0.8114\n",
            "Epoch 44/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6683 - loss: 1.0863\n",
            "Epoch 45/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6870 - loss: 0.9835\n",
            "Epoch 46/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8289 - loss: 0.8102\n",
            "Epoch 47/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7768 - loss: 0.8183\n",
            "Epoch 48/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6499 - loss: 1.1893\n",
            "Epoch 49/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7522 - loss: 0.8108\n",
            "Epoch 50/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7546 - loss: 0.7792\n",
            "Epoch 51/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7307 - loss: 0.7542\n",
            "Epoch 52/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7789 - loss: 0.8471\n",
            "Epoch 53/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7293 - loss: 0.8455\n",
            "Epoch 54/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6924 - loss: 0.9958\n",
            "Epoch 55/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7970 - loss: 0.7012\n",
            "Epoch 56/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7846 - loss: 0.7670\n",
            "Epoch 57/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7951 - loss: 0.6850\n",
            "Epoch 58/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7699 - loss: 0.6962\n",
            "Epoch 59/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7281 - loss: 0.7612\n",
            "Epoch 60/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7252 - loss: 0.8236\n",
            "Epoch 61/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7868 - loss: 0.7410\n",
            "Epoch 62/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8494 - loss: 0.4874\n",
            "Epoch 63/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8200 - loss: 0.5864\n",
            "Epoch 64/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8007 - loss: 0.6917\n",
            "Epoch 65/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7980 - loss: 0.7635\n",
            "Epoch 66/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7826 - loss: 0.7890\n",
            "Epoch 67/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8105 - loss: 0.6411\n",
            "Epoch 68/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.8389 - loss: 0.5638\n",
            "Epoch 69/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8007 - loss: 0.6095\n",
            "Epoch 70/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8526 - loss: 0.5171\n",
            "Epoch 71/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8152 - loss: 0.6537\n",
            "Epoch 72/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8271 - loss: 0.5650\n",
            "Epoch 73/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8184 - loss: 0.6816\n",
            "Epoch 74/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8198 - loss: 0.6541\n",
            "Epoch 75/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.7926 - loss: 0.5616\n",
            "Epoch 76/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7981 - loss: 0.5674\n",
            "Epoch 77/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.8447 - loss: 0.5894\n",
            "Epoch 78/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8409 - loss: 0.5836\n",
            "Epoch 79/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8247 - loss: 0.5779\n",
            "Epoch 80/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8465 - loss: 0.4876\n",
            "Epoch 81/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8464 - loss: 0.5462\n",
            "Epoch 82/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8345 - loss: 0.6040\n",
            "Epoch 83/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8328 - loss: 0.5750\n",
            "Epoch 84/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8181 - loss: 0.6728\n",
            "Epoch 85/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8316 - loss: 0.5360\n",
            "Epoch 86/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8758 - loss: 0.4453\n",
            "Epoch 87/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8672 - loss: 0.3874\n",
            "Epoch 88/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8350 - loss: 0.5656\n",
            "Epoch 89/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8600 - loss: 0.4247\n",
            "Epoch 90/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8738 - loss: 0.3932\n",
            "Epoch 91/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8714 - loss: 0.4736\n",
            "Epoch 92/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8582 - loss: 0.4188\n",
            "Epoch 93/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9019 - loss: 0.4115\n",
            "Epoch 94/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8474 - loss: 0.4879\n",
            "Epoch 95/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8435 - loss: 0.5114\n",
            "Epoch 96/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8655 - loss: 0.4396\n",
            "Epoch 97/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.8470 - loss: 0.5103\n",
            "Epoch 98/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8470 - loss: 0.5427\n",
            "Epoch 99/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.4031\n",
            "Epoch 100/100\n",
            "\u001b[1m47/47\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7975 - loss: 0.6431\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "training_data = []\n",
        "output_template = [0] * len(labels)\n",
        "#Build the bag-of-words model for each document in the corpus\n",
        "for sentence, label in corpus:\n",
        "    word_bag = []\n",
        "    tokenized_words = [lemmatizer.lemmatize(word.lower()) for word in sentence]\n",
        "\n",
        "    #Create binary word occurrence representation (bag of words)\n",
        "    word_bag = [1 if word in tokenized_words else 0 for word in vocab]\n",
        "    output_row = list(output_template)\n",
        "    output_row[labels.index(label)] = 1\n",
        "    training_data.append([word_bag, output_row])\n",
        "\n",
        "random.shuffle(training_data)\n",
        "training_data = np.array(training_data, dtype=object)\n",
        "\n",
        "\n",
        "X_train = np.array([item[0] for item in training_data])  #Input patterns(bag of words)\n",
        "y_train = np.array([item[1] for item in training_data])  #Target intents(one-hot)\n",
        "print(\"Training data is ready.\")\n",
        "\n",
        "#neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(128, input_shape=(len(X_train[0]),), activation='relu'))  # First dense layer\n",
        "model.add(Dropout(0.5))  #Regularization with dropout\n",
        "model.add(Dense(64, activation='relu'))  #Second dense layer\n",
        "model.add(Dropout(0.5))  #Dropout for overfitting prevention\n",
        "model.add(Dense(len(y_train[0]), activation='softmax'))  # Output layer with softmax\n",
        "optimizer = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "history = model.fit(np.array(X_train), np.array(y_train), epochs=100, batch_size=5, verbose=1)\n",
        "model.save('mental_health_bot_model.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "CkYdDPflkWCv"
      },
      "outputs": [],
      "source": [
        "#Tokenize and lemmatize the input sentence\n",
        "def clean_up_sentence(sentence):\n",
        "    sentence_words = nltk.word_tokenize(sentence)  # Split sentence into words\n",
        "    return [lemmatizer.lemmatize(word.lower()) for word in sentence_words]  # Lemmatize and lowercase\n",
        "\n",
        "#Convert the sentence into a bag-of-words representation\n",
        "def bow(sentence, words, show_details=True):\n",
        "    sentence_words = clean_up_sentence(sentence)  #Process input sentence\n",
        "    bag = [0] * len(words)  #Initialize bag of words with 0s\n",
        "    for s in sentence_words:\n",
        "        for i, w in enumerate(words):\n",
        "            if w == s:\n",
        "                bag[i] = 1\n",
        "                if show_details:\n",
        "                    print(f\"Found in bag: {w}\")\n",
        "    return np.array(bag)\n",
        "\n",
        "#Predict the intent based on the input sentence\n",
        "def predict_class(sentence, histogram):\n",
        "    p = bow(sentence, words, show_details=False)  #Get bag of words\n",
        "    res = model.predict(np.array([p]))[0]  #Predict intent probability\n",
        "    ERROR_THRESHOLD = 0.25\n",
        "    results = [[i, r] for i, r in enumerate(res) if r > ERROR_THRESHOLD]\n",
        "    #Sort results by probability\n",
        "    results.sort(key=lambda x: x[1], reverse=True)\n",
        "    #Convert results to list of intents with probabilities\n",
        "    return [{\"intent\": classes[r[0]], \"probability\": str(r[1])} for r in results]\n",
        "\n",
        "#Generate a response based on predicted intent\n",
        "def getResponse(ints, intents_json):\n",
        "    if not ints:\n",
        "        return \"I'm sorry, I don't understand. Could you rephrase that?\"\n",
        "\n",
        "    tag = ints[0]['intent']  #Get the top predicted intent\n",
        "    for i in intents_json['intents']:\n",
        "        if i['tag'] == tag:\n",
        "            return random.choice(i['responses'])  #Return random response for the intent\n",
        "\n",
        "    return \"I'm sorry, I don't understand. Could you rephrase that?\"\n",
        "\n",
        "def respond(message):\n",
        "    ints = predict_class(message, model)\n",
        "    return getResponse(ints, intents)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "JEf2e5Os6-vR",
        "outputId": "3464128d-660f-4e87-edb5-cc16bdbeba96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://5e6d095b01047a2565.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div><iframe src=\"https://5e6d095b01047a2565.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Create a Gradio Interface\n",
        "iface = gr.Interface(\n",
        "    fn=respond,\n",
        "    inputs=gr.Textbox(\n",
        "        lines=2,\n",
        "        placeholder=\"Type your message here...\",\n",
        "        label=\"Your Message\"\n",
        "    ),\n",
        "    outputs=gr.Textbox(\n",
        "        label=\"Bot's Response\"\n",
        "    ),\n",
        "    title=\"🧠 Mental Health Chatbot\",\n",
        "    description=\"Interact with our mental health chatbot. Type your message and get a response!\",\n",
        "\n",
        ")\n",
        "\n",
        "iface.launch()\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
